{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5101775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "#from sklearn.metrics import r2_score\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available else torch.device('cpu')\n",
    "print(device)\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "plt.style.use(\"seaborn-talk\") #\"classic\" \"seaborn-talk\" \"seaborn\"\n",
    "path_to_h5 =  \"/home/leonov/Baikal/Cut_8_nu/APRIL/Ordered/Data/mc_baikal_norm_cut-8_ordered_equal_big.h5\"\n",
    "#Baikal/Cut_8_nu/APRIL/Ordered/Data\n",
    "# можно отделить хвост и отдельно прогнать его по другой сетке\n",
    "def make_trainset_noxyz(i, di = 1, tr_set_len = 128,Batch_size = 64):\n",
    "    with h5py.File(path_to_h5, 'r') as hf:\n",
    "            Data = hf['train/data/'][i*int(tr_set_len) : (i+di)*int(tr_set_len),:32]\n",
    "            Polar=hf[\"/train/ev_chars\"][i*int(tr_set_len) : (i+di)*int(tr_set_len),0]*(np.pi)/180\n",
    "            Azimut=hf[\"/train/ev_chars\"][i*int(tr_set_len) : (i+di)*int(tr_set_len),1]*(np.pi)/180\n",
    "            x=np.expand_dims(np.sin(Polar)*np.cos(Azimut),axis=1)\n",
    "            y=np.expand_dims(np.sin(Polar)*np.sin(Azimut),axis=1)\n",
    "            z=np.expand_dims(np.cos(Polar),axis=1)\n",
    "            target=torch.FloatTensor(np.concatenate((x,y,z) ,axis=1))\n",
    "            Data = torch.FloatTensor(Data.swapaxes(1, -1)) # надо,т.к. второй индекс должен быть количеством   последовательностей\n",
    "            trainDataset = torch.utils.data.TensorDataset(Data, target)\n",
    "            trainLoader = torch.utils.data.DataLoader(dataset = trainDataset, batch_size=Batch_size) #,sampler = sampler    \n",
    "    return  trainLoader\n",
    "def make_valset_noxyz(i=0, di = 1, tr_set_len = 1000, Batch_size = 64):\n",
    "    with h5py.File(path_to_h5, 'r') as hf:\n",
    "            Data = hf['val/data/'][i*int(tr_set_len) : (i+di)*int(tr_set_len),:32] # ибо очень редко как то задействовано более чем 32 OM\n",
    "            Data = torch.FloatTensor(Data.swapaxes(1, -1)) \n",
    "            Polar=hf[\"/val/ev_chars\"][i*int(tr_set_len) : (i+di)*int(tr_set_len),0]*(np.pi)/180\n",
    "            Azimut=hf[\"/val/ev_chars\"][i*int(tr_set_len) : (i+di)*int(tr_set_len),1]*(np.pi)/180\n",
    "            #\n",
    "            x=np.expand_dims(np.sin(Polar)*np.cos(Azimut),axis=1)\n",
    "            y=np.expand_dims(np.sin(Polar)*np.sin(Azimut),axis=1)\n",
    "            z=np.expand_dims(np.cos(Polar),axis=1)\n",
    "            target=torch.FloatTensor(np.concatenate((x,y,z) ,axis=1))\n",
    "            testDataset = torch.utils.data.TensorDataset(Data, target)\n",
    "            testLoader = torch.utils.data.DataLoader(dataset = testDataset, batch_size=Batch_size)\n",
    "    return testLoader\n",
    "# вектора в углы\n",
    "def v_to_angles( Predicted, Real,\n",
    "                p_hist, az_hist, p_error_hist,\n",
    "                to_hists = True): \n",
    "    #Predict = torch.nn.functional.normalize(model(torch.Tensor(Predict).to(device).float() )).cpu().detach().numpy()\n",
    "    v_pred = torch.nn.functional.normalize(Predicted.detach()) # нормализую\n",
    "    #полярный получаю просто и в градусах\n",
    "    polar_real = torch.acos(Real[:,-1])/(np.pi)*180 \n",
    "    polar_predicted = torch.acos(v_pred[:,-1])/(np.pi)*180 \n",
    "    # azimut\n",
    "    azimut =torch.acos( v_pred[:,0]/((v_pred[:,0])**2+(v_pred[:,1])**2+1e-8)**0.5 ) # добавляю  в знаменатель добавку чтоб наны не получить\n",
    "    azimut = azimut+(torch.sign(v_pred[:,1])**2)*(1-torch.sign(v_pred[:,1]))*(np.pi-azimut) # torch.sign(v[:,1])**2 на случай нулевых углов,которых нет\n",
    "    azimut = azimut/(np.pi)*180 # привожу к градусам\n",
    "    if not to_hists: \n",
    "        return polar,azimut\n",
    "    azimut=azimut.short()\n",
    "    #polar = polar.short()\n",
    "    for pol_pred, pol_real, az in zip(polar_predicted, polar_real, azimut):\n",
    "        p_error_hist[round(abs((pol_pred-pol_real).item()),1)] += 1\n",
    "        p_hist[pol_pred.short().item()] += 1\n",
    "        az_hist[az.item()] += 1\n",
    "#{k:0 for k in np.arange(0.0, 180, 0.1)}     \n",
    "def resolution_calculation(v1,v2,hist,to_hist = True):\n",
    "    v1, v2 = v1.double(), v2.double()    \n",
    "    if not to_hist:\n",
    "        return torch.acos(torch.nn.functional.cosine_similarity(v1,v2,dim = 1))/np.pi*180\n",
    "    res = torch.acos(torch.nn.functional.cosine_similarity(v1,v2,dim = 1))/np.pi*180\n",
    "    res = torch.nn.functional.cosine_similarity(v1,v2,dim = 1)\n",
    "    res = torch.acos(res)/np.pi*180\n",
    "    for res_value in res:\n",
    "        try:\n",
    "                hist[round(res_value.item(),1)] += 1\n",
    "        except KeyError:\n",
    "            hist[0.0] += 1\n",
    "            print(res_value.item(),\"torch is bad at acos calculation\")\n",
    "            #print(res_value)\n",
    "            #print(\"v1 = \" ,v1, v1.shape ,\"v2 = \", v2, v2.shape,\n",
    "            #      \"res_value = \",res_value, res_value.shape,\"res = \",\n",
    "            #      res,res.shape,\"res_value_round = \", round(res_value.item(),1), sep= \"\\n\")\n",
    "            #print(torch.nn.functional.cosine_similarity(v1,v2,dim = 1))\n",
    "            #raise KeyError\n",
    "def loss_plot(list_test, list_train , path , save = True):\n",
    "    plt.figure(figsize=(9,6))\n",
    "    plt.plot(np.arange(len(list_test)), list_test, label='val', linewidth=2)\n",
    "    plt.plot(np.arange(len(list_train)), list_train, label='train', linewidth=2)\n",
    "    plt.title('Loss_plot')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    if save == True:\n",
    "        plt.savefig(path)\n",
    "    plt.show()\n",
    "def res_plot(train_dict,val_dict, path = None,save = True, res_or_polar = \"Resolution \" ,size= 13):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    colours=[\"red\",\"red\"]\n",
    "    names = [\"train\" , \"val\"]\n",
    "    for i, d in enumerate([train_dict,val_dict]):\n",
    "        plt.subplot(1,2,i+1)\n",
    "        s = sum(d.values())\n",
    "        prep_inter_s ,inter_s = 0, 0\n",
    "        res_50, res_68 =0,0\n",
    "        for key in list(d.keys()):\n",
    "            if inter_s/s >= 0.68:\n",
    "                alpha = (inter_s-0.68*s)/(inter_s-prep_inter_s) # alpha*inter_s+(1-alpha)*prep_inter_s == 0.68*s\n",
    "                res_68 =round(key + 0.1*alpha,2)  #alpha*(key-0.1)+(1-alpha)*(key)\n",
    "                break\n",
    "            if inter_s/s >= 0.5 and res_50 == 0:\n",
    "                alpha = (inter_s-0.5*s)/(inter_s-prep_inter_s)\n",
    "                res_50 =round(key + 0.1*alpha,2)\n",
    "            prep_inter_s = inter_s \n",
    "            inter_s  += d[key]  \n",
    "        a=plt.step(list(d.keys())[:300], list(d.values())[:300], color=colours[i],alpha = 0.6)\n",
    "        plt.bar(res_50, max(d.values()), width=0.5,label=names[i] + \"50%\" + res_or_polar +\"= \"+str(res_50),\n",
    "                color=\"yellow\" , alpha =0.7 )\n",
    "        plt.bar(res_68, max(d.values()), width=0.5,label=names[i] + \"68%\" + res_or_polar +\" = \"+str(res_68) ,\n",
    "                color=\"orange\",alpha = 0.7)\n",
    "        plt.legend()\n",
    "        plt.xlabel(res_or_polar + \"in_grad\",fontsize= size); plt.title(res_or_polar + names[i],fontsize= size)\n",
    "    if save == True:\n",
    "        plt.savefig(path) \n",
    "    plt.show()\n",
    "\n",
    "def angle_hist(hist_polar,hist_azimut,path, save =True,size= 13,name = \"train\"):\n",
    "    with h5py.File(path_to_h5, 'r') as hf:\n",
    "        plt.figure(figsize= (13,10))\n",
    "        sum_value = sum(hist_polar.values())\n",
    "        Polar=hf[\"/\"+name+\"/ev_chars\"][ : ,0] \n",
    "        Azimut=hf[\"/\"+name+\"/ev_chars\"][ : ,1]\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.hist(Polar,bins=180,label=name+\" Polar\",density=True,histtype=\"step\",color=\"blue\")\n",
    "        plt.bar(list(hist_polar.keys())[:100], np.array(list(hist_polar.values())[:100])/sum_value, \n",
    "                color=\"red\",label=name+\" Polar_Predicted\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Polar_Angle\",fontsize= size); plt.title(name+\"_Polar\",fontsize= size)\n",
    "        plt.subplot(2,1,2) \n",
    "        plt.hist(Azimut,bins=360,label=name+\" Azimut\",density=True,histtype=\"step\",color=\"blue\")\n",
    "        plt.bar(list(hist_azimut.keys()), np.array(list(hist_azimut.values()))/sum_value,\n",
    "                    align = 'center', color=\"red\",label=name+\" Azimut_Predicted\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Azimut_Angle\",fontsize= size) ;plt.title(name+\"_Azimut\",fontsize= size)\n",
    "        if save == True:\n",
    "            plt.savefig(path) \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c70e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_set_len = 512*100\n",
    "seq = [j for j in range(int( 1881011/tr_set_len))]\n",
    "print('Num of sub-epochs in Epoch = ', len(seq), '\\n')\n",
    "len_seq = len(seq)\n",
    "\n",
    "#Определяем модель\n",
    "#model = Net.to(device)\n",
    "def fitting(model, scheduler_Exp, scheduler_MultiStep , optimizer,\n",
    "        epochs_num = 25, batch_size = 64,\n",
    "        criterion=torch.nn.L1Loss(),\n",
    "        save_weights = True, save_plot = True, save_resolution = True,  save_angles = True, save_polar_error = True,   \n",
    "        suffix = \"Nu_MAE_Res_1D\",\n",
    "        path_begin = \"/home/leonov/Baikal/Cut_8_nu/APRIL/Ordered\"\n",
    "           ):\n",
    "    #optimizer = torch.optim.Adam(model.parameters(),lr=learn_rate)\n",
    "    #scheduler_Exp = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=1)\n",
    "    #scheduler_MultiStep = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[10,20,30,40,42], gamma=0.5) \n",
    "    loss_train = []\n",
    "    loss_test = []\n",
    "    hist_train_polar_error = {round(k,1):0 for k in np.arange(0.0, 180, 0.1)} # здесь будут polar error всех событий\n",
    "    hist_val_polar_error = {round(k,1):0 for k in np.arange(0.0, 180, 0.1)}\n",
    "    hist_train_res = {round(k,1):0 for k in np.arange(0.0, 180, 0.1)} # здесь будут гистограммы  разрешения всех событий\n",
    "    hist_val_res = {round(k,1):0 for k in np.arange(0.0, 180, 0.1)}    \n",
    "    hist_train_polar = {k:0 for k in np.arange(0, 181, 1)} # гистограммы  предсказанных углов для сравнения с реальным распределением \n",
    "    hist_train_azimut = {k:0 for k in np.arange(0, 361, 1)}\n",
    "    hist_val_polar = {k:0 for k in np.arange(0, 181, 1)} \n",
    "    hist_val_azimut = {k:0 for k in np.arange(0, 361, 1)}    \n",
    "    num = 0\n",
    "    for n in range(1, epochs_num+1):\n",
    "        #training\n",
    "        print('\\n','Indeed Epoch = ', n)\n",
    "        for i in seq:\n",
    "            train_Loader = make_trainset_noxyz(i,1,tr_set_len,Batch_size = batch_size)\n",
    "            for x_batch,y_batch in train_Loader:\n",
    "                optimizer.zero_grad()\n",
    "                outp = model(x_batch.to(device).float())\n",
    "                loss =   criterion(outp,y_batch.to(device).float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # полученный вектор направления превращаю в углы и добавляю в гистограммы\n",
    "                if n == epochs_num:\n",
    "                    v_to_angles(Predicted = outp, Real = y_batch.to(device), p_error_hist = hist_train_polar_error,\n",
    "                                p_hist = hist_train_polar, az_hist = hist_train_azimut, to_hists = True)\n",
    "                    resolution_calculation(outp,y_batch.to(device),hist = hist_train_res,to_hist = True)\n",
    "            if (num%(len_seq//3) == 0):\n",
    "                rand_ind=np.random.randint(0,15)\n",
    "                print('Sub-epoch number = ', num)\n",
    "                loss_train.append(loss.item())\n",
    "                model.eval()\n",
    "                testLoader = make_valset_noxyz(rand_ind,1,500, Batch_size = batch_size)\n",
    "                test_loss=0\n",
    "                count=0\n",
    "                for x_test_batch,y_test_batch in testLoader:\n",
    "                    outp = model(x_test_batch.to(device).float())\n",
    "                    test_loss +=  criterion(outp,y_test_batch.to(device).float()).item()\n",
    "                    count+=1\n",
    "                test_loss /=count\n",
    "                loss_test.append(test_loss)\n",
    "                model.train()\n",
    "                print(\"train_loss = \",loss.item(),\"  val_loss = \",test_loss)\n",
    "            num+=1\n",
    "        scheduler_Exp.step()\n",
    "        scheduler_MultiStep.step()\n",
    "        \n",
    "    model.eval()\n",
    "    FinalLoader = make_valset_noxyz(0,-1,1, Batch_size = batch_size) # делаю  loader из всего датасета\n",
    "    for x_test_batch,y_test_batch in FinalLoader:\n",
    "        outp = model(x_test_batch.to(device).float())\n",
    "        v_to_angles(Predicted = outp, Real = y_test_batch.to(device), p_error_hist = hist_val_polar_error,\n",
    "                    to_hists = True,p_hist = hist_val_polar, az_hist = hist_val_azimut)\n",
    "        resolution_calculation(outp, y_test_batch.to(device), hist = hist_val_res, to_hist = True)\n",
    "        \n",
    "    if save_weights == True:\n",
    "        torch.save(model.state_dict(), path_begin + \"/states/\" + suffix + \"model\")\n",
    "        torch.save(optimizer.state_dict(), path_begin + \"/states/\" + suffix + \"opt\")\n",
    "    # график лосса\n",
    "    loss_plot(loss_test, loss_train , path_begin + \"/Images/Loss/\" + suffix + \"LOSS.png\", \n",
    "              save_plot )\n",
    "    #  гистограмма ошибок  полярного угла\n",
    "    res_plot(hist_train_polar_error, hist_val_polar_error, \n",
    "             path = path_begin + \"/Images/Polar_Error/\" + suffix+ \"Polar_Error.png\",\n",
    "             save = save_polar_error, res_or_polar = \"Polar_Error \")    \n",
    "    # гистограммы разрешения\n",
    "    res_plot(hist_train_res,hist_val_res,\n",
    "             path = path_begin + \"/Images/Resolution/\" + suffix + \"RESOLUTIONS.png\",\n",
    "             save = save_resolution,res_or_polar = \"Resolution \")\n",
    "    #гистограммы углов\n",
    "    angle_hist(hist_train_polar,hist_train_azimut, name='train',\n",
    "               path = path_begin + \"/Images/Angles/\" + suffix + \"Angles_train.png\", \n",
    "               save = save_angles)\n",
    "    angle_hist(hist_val_polar,hist_val_azimut, name='val',\n",
    "               path = path_begin + \"/Images/Angles/\" + suffix + \"Angles_val.png\", \n",
    "               save = save_angles)\n",
    "    loss_lists = [loss_train , loss_test]\n",
    "    polar_hists = [hist_train_polar , hist_val_polar]\n",
    "    azimut_hists = [hist_train_azimut, hist_val_azimut]\n",
    "    res_hists = [hist_train_res ,hist_val_res]\n",
    "    polar_error = [hist_train_polar_error, hist_val_polar_error]\n",
    "    model.train()\n",
    "    return  loss_lists, polar_hists, azimut_hists ,res_hists ,polar_error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c89221d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 160])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ResNet_Block(torch.nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super().__init__()\n",
    "        self.module = torch.nn.Sequential(    \n",
    "            torch.nn.Conv1d(input_size, input_size*2,  kernel_size=3, stride=1,padding=1),\n",
    "            torch.nn.BatchNorm1d(input_size*2),\n",
    "            torch.nn.PReLU(),\n",
    "            torch.nn.Conv1d(input_size*2, input_size*2,  kernel_size=3, stride=1,padding=1),\n",
    "            torch.nn.BatchNorm1d(input_size*2),\n",
    "            torch.nn.PReLU(),\n",
    "            torch.nn.Conv1d(input_size*2,input_size,  kernel_size=3, stride= 1 ,padding=1),\n",
    "            torch.nn.BatchNorm1d(input_size),\n",
    "            torch.nn.PReLU()\n",
    "          )\n",
    "        self.conv = torch.nn.Sequential( \n",
    "            torch.nn.Conv1d(input_size, input_size, kernel_size =1),\n",
    "            torch.nn.PReLU()\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "          return  (self.module(inputs) +self.conv(inputs))\n",
    "\n",
    "net = torch.nn.Sequential(    \n",
    "    torch.nn.Conv1d(5, 5,  kernel_size= 3 , stride = 1 ,padding= 1 ),\n",
    "    torch.nn.BatchNorm1d(5),\n",
    "    torch.nn.PReLU(),\n",
    "    ResNet_Block(5),\n",
    "    Transition_Block(5), #16\n",
    "    ResNet_Block(10), #16\n",
    "    Transition_Block(10), #8\n",
    "    ResNet_Block(20),\n",
    "    Transition_Block(20), #4\n",
    "    ResNet_Block(40),  \n",
    "    torch.nn.Flatten(),\n",
    "    \n",
    ")\n",
    "a = torch.ones((512,5 ,32))\n",
    "net(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44e1d9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65240"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ResNet_Block(torch.nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super().__init__()\n",
    "        self.module = torch.nn.Sequential(    \n",
    "            torch.nn.Conv1d(input_size, input_size*2,  kernel_size=3, stride=1,padding=1),\n",
    "            torch.nn.BatchNorm1d(input_size*2),\n",
    "            torch.nn.PReLU(),\n",
    "            torch.nn.Conv1d(input_size*2, input_size*2,  kernel_size=3, stride=1,padding=1),\n",
    "            torch.nn.BatchNorm1d(input_size*2),\n",
    "            torch.nn.PReLU(),\n",
    "            torch.nn.Conv1d(input_size*2,input_size,  kernel_size=3, stride= 1 ,padding=1),\n",
    "            torch.nn.BatchNorm1d(input_size),\n",
    "            torch.nn.PReLU()\n",
    "          )\n",
    "        self.conv = torch.nn.Sequential( \n",
    "            torch.nn.Conv1d(input_size, input_size, kernel_size =1),\n",
    "            torch.nn.PReLU()\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "          return  (self.module(inputs) +self.conv(inputs))\n",
    "class Transition_Block(torch.nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super().__init__()\n",
    "        self.trans_module = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(input_size, input_size*2, kernel_size=3, stride=2,padding=1 ),\n",
    "            torch.nn.BatchNorm1d(num_features=input_size*2),\n",
    "            torch.nn.PReLU()\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        return  self.trans_module(inputs) \n",
    "    \n",
    "\n",
    "a = torch.ones((512,5 ,32))\n",
    "net = torch.nn.Sequential(    \n",
    "    torch.nn.Conv1d(5, 5,  kernel_size= 3 , stride = 1 ,padding= 1 ),\n",
    "    torch.nn.BatchNorm1d(5),\n",
    "    torch.nn.PReLU(),\n",
    "    ResNet_Block(5), #32\n",
    "    Transition_Block(5), #16\n",
    "    ResNet_Block(10), #16\n",
    "    Transition_Block(10), #8\n",
    "    ResNet_Block(20),\n",
    "    Transition_Block(20), #4\n",
    "    ResNet_Block(40), # 4\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(160,40),\n",
    "    torch.nn.BatchNorm1d(40),\n",
    "    torch.nn.PReLU(),\n",
    "    torch.nn.Linear(40,20),\n",
    "    torch.nn.BatchNorm1d(20),\n",
    "    torch.nn.PReLU(),\n",
    "    torch.nn.Linear(20 ,3)\n",
    ") \n",
    "\n",
    "\n",
    "#net(a).shape\n",
    "sum(p.numel() for p in net.parameters()   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.to(device)\n",
    "learn_rate =6e-3\n",
    "opt = torch.optim.Adam(model.parameters(),lr=learn_rate)\n",
    "sch_Exp = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.99)\n",
    "sch_MultiStep = torch.optim.lr_scheduler.MultiStepLR(opt,milestones=[10,20,30,40,45], gamma=0.7) \n",
    "loss_lists, polar_hists, azimut_hists ,res_hists ,polar_error =fitting(model,sch_Exp , sch_MultiStep, opt,\n",
    "                                                                       suffix = \"Nu_MAE_Res_1D\",\n",
    "                                                                       epochs_num=10, batch_size =64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
